# **Use Case 3.1**



## âœ¨ **Beschreibung**

**Use Case 3.1** ist ein fortschrittliches System, das eine dreifache Validierungsarchitektur verwendet. Ziel ist es, Inhalte mit maximaler PrÃ¤zision zu erstellen und zu Ã¼berprÃ¼fen, indem drei unabhÃ¤ngige Validierungsagenten gleichzeitig arbeiten. Dieser Ansatz gewÃ¤hrleistet hÃ¶chste QualitÃ¤t und ZuverlÃ¤ssigkeit der generierten Inhalte. 

Hauptmerkmale dieses Use Cases:

1. **Inhaltserstellung**: Erstellung von strukturierten und detaillierten Texten basierend auf einem komplexen Prompt.
2. **Dreifache Validierung**: Inhalte werden von drei Agenten geprÃ¼ft, um unterschiedliche Perspektiven und PrÃ¼fmethoden zu berÃ¼cksichtigen.
3. **Erweiterte Analyse**: Fokus auf sprachliche, strukturelle und inhaltliche Genauigkeit.

---

## ğŸ§  **Verwendetes KI-Modell**

Das Modell **`llama-3.2-3b-instruct`** wird in **Use Case 3.1** eingesetzt. Seine Hauptvorteile sind:

- **Effizienz in der Textverarbeitung**.
- **Hohe PrÃ¤zision** bei der Generierung umfangreicher und komplexer Inhalte.
- **UnterstÃ¼tzung fÃ¼r grÃ¶ÃŸere Kontexte**, ideal fÃ¼r mehrstufige Validierungen.

---

## ğŸ¤– **Agenten im Einsatz**

In **Use Case 3.1** werden drei Validierungsagenten eingesetzt, die unabhÃ¤ngig voneinander arbeiten, um eine tiefgehende und umfassende PrÃ¼fung sicherzustellen. Die Aufgaben sind wie folgt:

1. **Agent 1**: Fokussiert auf sprachliche und grammatikalische ÃœberprÃ¼fung.
2. **Agent 2**: Bewertet die Struktur und KohÃ¤renz des Textes.
3. **Agent 3**: Fokussiert auf inhaltliche Genauigkeit und Relevanz.

Die Zusammenarbeit dieser Agenten ermÃ¶glicht eine vielschichtige Validierung und stellt sicher, dass alle Aspekte des Textes von hÃ¶chster QualitÃ¤t sind.

---

## ğŸ”„ **Unterschiede zu Use Case 2**

1. **Anzahl der Agenten**:
   - **Use Case 2.1/2.2**: Zwei Agenten.
   - **Use Case 3.1**: Drei Agenten.

2. **Validierungsprozesse**:
   - **Use Case 2.1/2.2**: Duale Validierung mit grundlegenden und erweiterten PrÃ¼fungen.
   - **Use Case 3.1**: Dreifache Validierung mit spezifischen PrÃ¼fbereichen fÃ¼r jeden Agenten.

3. **Anwendungsszenarien**:
   - **Use Case 2.1/2.2**: FÃ¼r komplexe, aber kleinere Projekte geeignet.
   - **Use Case 3.1**: Optimal fÃ¼r Projekte mit hÃ¶chsten QualitÃ¤tsanforderungen und umfangreichen Inhalten.

---

## ğŸ›  **Besonderheiten von Use Case 3.1**

- **Dreifache-Agenten-Architektur**: Maximale Genauigkeit durch spezialisierte PrÃ¼fungen.
- **HÃ¶chste QualitÃ¤tsstandards**: Geeignet fÃ¼r Projekte mit hÃ¶chsten Anforderungen an sprachliche, strukturelle und inhaltliche PrÃ¤zision.
- **FlexibilitÃ¤t und Tiefe**: Ideal fÃ¼r umfangreiche und anspruchsvolle Textprojekte.

---

## ğŸš€ **Anleitung zur AusfÃ¼hrung**

### **Voraussetzungen**

- **Python-Version**: 3.10
- **LM Studio** (mit Modellen, die mindestens 128k Token unterstÃ¼tzen)

### **Installation**

1. **AbhÃ¤ngigkeiten installieren**:

   ```bash
   pip install -r requirements.txt
   ```

2. **LM Studio einrichten**:
   - Gehe zum **Developer Tab**.
   - WÃ¤hle das Modell **`llama-3.2-3b-instruct`** aus.
   - Passe die **Context Length** an (Standard: 55k, fÃ¼r lÃ¤ngere Inhalte: 128k).
   - Lade das Modell und Ã¶ffne die **Servereinstellungen**:
     - Port: `1234`
     - **Enable CORS** aktivieren.

### **AusfÃ¼hrung**

FÃ¼hre das Projekt mit folgendem Befehl aus:

```bash
python main.py
```

---

## ğŸŒŸ **Ergebnisse**

Nach der AusfÃ¼hrung finden Sie die generierten Inhalte im Ordner **`Ergebnisse`**. StandardmÃ¤ÃŸig wird der Inhalt anhand eines Prompts wie:

> *"Erstelle einen ausfÃ¼hrlichen Bericht Ã¼ber die Entwicklung und Auswirkungen von kÃ¼nstlicher Intelligenz."*

erstellt. Die Inhalte durchlaufen alle drei Validierungsstufen und werden abschlieÃŸend gespeichert.

---

## ğŸ“‚ **Projektstruktur**

### **Hauptverzeichnis**

- **`README.md`**: Diese Datei mit allen Anweisungen und Beschreibungen.
- **`requirements.txt`**: Liste aller AbhÃ¤ngigkeiten fÃ¼r das Projekt.
- **`Ergebnisse/`**: Ordner, in dem die generierten Inhalte gespeichert werden.
- **`backend/`**: Beinhaltet die Hauptlogik des Projekts.

### **Backend-Verzeichnis**

Das `backend/`-Verzeichnis enthÃ¤lt folgende Dateien:

1. **`backend.py`**: Die zentrale Steuerungseinheit fÃ¼r die Verarbeitung der Prompts und Generierung der Inhalte.
2. **`chatAgent.py`**: Implementierung der spezialisierten Validierungsagenten.
3. **`main.py`**: Einstiegspunkt fÃ¼r die AusfÃ¼hrung des Use Cases. Hier werden alle Module geladen und der Ablauf gesteuert.
4. **`agent.py`**: Kernkomponenten fÃ¼r die KI-Interaktion, die die Kommunikation zwischen Modell und Backend erleichtern.
5. **`duckduckgo.py`**: Modul zur Integration von externen Suchdiensten, um die Generierung mit zusÃ¤tzlichem Wissen zu unterstÃ¼tzen.
6. **`ollama.py`**: Ein Modul, das spezifisch fÃ¼r die Interaktion mit dem `llama-3.2-3b-instruct` Modell optimiert wurde.

### **Ergebnisse-Verzeichnis**

- **`Use_Case_3.1.txt`**: Standarddatei, in der die Inhalte gespeichert werden, die aus diesem Use Case generiert wurden.

---

## ğŸ“ **Hinweis**

Dieses Projekt wurde so konzipiert, dass es lokal ausgefÃ¼hrt werden kann, um unnÃ¶tige Abfragen an externe Server zu vermeiden. Dies gewÃ¤hrleistet hÃ¶here Sicherheit und schnellere Verarbeitung.

---
