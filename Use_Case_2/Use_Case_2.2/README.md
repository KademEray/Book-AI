# **Use Case 2.2**



## âœ¨ **Beschreibung**

**Use Case 2.2** stellt eine weitere Iteration der dualen Validierungsarchitektur dar, wobei ein noch umfassenderer Ansatz zur Erstellung und ÃœberprÃ¼fung von Inhalten verfolgt wird. Dieses System nutzt fortschrittlichere Validierungsalgorithmen und spezialisierte Agenten, um eine tiefere Analyse und genauere Ergebnisse zu gewÃ¤hrleisten. Die Hauptaspekte dieses Use Cases sind:

1. **Erweiterte Inhaltserstellung**: Erzeugung von detaillierten und komplexen Texten basierend auf einem vorgegebenen Prompt.
2. **Verfeinerte Dual-Validierung**: Zwei Agenten arbeiten mit erweiterten PrÃ¼fmechanismen, um die generierten Inhalte kritisch zu analysieren.
3. **Optimierung durch spezielle Modelle**: Einsatz des Modells **`dolphin3.0-llama3.1-8b`**, das fÃ¼r komplexe Textgenerierung entwickelt wurde.

---

## ğŸ§  **Verwendetes KI-Modell**

Das Modell **`dolphin3.0-llama3.1-8b`** ist speziell fÃ¼r folgende Zwecke optimiert:

- **Erstellung hochkomplexer Inhalte**.
- **Erweiterte Kontextverarbeitung** fÃ¼r lÃ¤ngere AbsÃ¤tze und detaillierte Kapitel.
- **Fortschrittliche ValidierungsunterstÃ¼tzung**, die ideal fÃ¼r kritische Anwendungen ist.

---

## ğŸ¤– **Agenten im Einsatz**

In **Use Case 2.2** kommen zwei spezialisierte **Validierungsagenten** zum Einsatz, die eine tiefere Analyse der Inhalte ermÃ¶glichen. Die Funktionen umfassen:

1. **Erstellung**: Inhalte werden basierend auf einem komplexen Prompt erstellt.
2. **PrÃ¼fung durch Agent 1**: Der erste Agent analysiert die Inhalte auf strukturelle KohÃ¤renz und sprachliche Korrektheit.
3. **PrÃ¼fung durch Agent 2**: Der zweite Agent fÃ¼hrt eine inhaltliche Validierung durch, einschlieÃŸlich FaktenÃ¼berprÃ¼fung und Relevanzbewertung.

Die Zusammenarbeit dieser Agenten gewÃ¤hrleistet, dass die Inhalte sowohl technisch als auch inhaltlich einwandfrei sind.

---

## ğŸ”„ **Unterschiede zu Use Case 2.1**

1. **Verwendetes Modell**:
   - **Use Case 2.1**: `llama-3.2-3b-instruct`
   - **Use Case 2.2**: `dolphin3.0-llama3.1-8b` (leistungsstÃ¤rker, ideal fÃ¼r komplexe Texte).

2. **Validierungsprozesse**:
   - **Use Case 2.1**: Standard-Dual-Validierung.
   - **Use Case 2.2**: Erweiterte PrÃ¼fmechanismen und tiefere Analyse.

3. **Anwendungsszenarien**:
   - **Use Case 2.1**: Geeignet fÃ¼r kÃ¼rzere und weniger komplexe Inhalte.
   - **Use Case 2.2**: Optimal fÃ¼r ausfÃ¼hrliche und anspruchsvolle Projekte.

---

## ğŸ›  **Besonderheiten von Use Case 2.2**

- **Fortgeschrittene Dual-Agenten-Architektur**: Noch detailliertere PrÃ¼fungen durch spezialisierte Agenten.
- **HÃ¶here PrÃ¤zision**: Dank des optimierten Modells und fortschrittlicher Algorithmen.
- **Skalierbarkeit**: Eignet sich fÃ¼r Projekte mit umfangreichen Anforderungen und groÃŸen Datenmengen.

---

## ğŸš€ **Anleitung zur AusfÃ¼hrung**

### **Voraussetzungen**

- **Python-Version**: 3.10
- **LM Studio** (mit Modellen, die mindestens 128k Token unterstÃ¼tzen)

### **Installation**

1. **AbhÃ¤ngigkeiten installieren**:

   ```bash
   pip install -r requirements.txt
   ```

2. **LM Studio einrichten**:
   - Gehe zum **Developer Tab**.
   - WÃ¤hle das Modell **`dolphin3.0-llama3.1-8b`** aus.
   - Passe die **Context Length** an (Standard: 55k, fÃ¼r lÃ¤ngere Inhalte: 128k).
   - Lade das Modell und Ã¶ffne die **Servereinstellungen**:
     - Port: `1234`
     - **Enable CORS** aktivieren.

### **AusfÃ¼hrung**

FÃ¼hre das Projekt mit folgendem Befehl aus:

```bash
python main.py
```

---

## ğŸŒŸ **Ergebnisse**

Nach der AusfÃ¼hrung finden Sie die generierten Inhalte im Ordner **`Ergebnisse`**. StandardmÃ¤ÃŸig wird der Inhalt anhand eines Prompts wie:

> *"Erstelle mir eine detaillierte Analyse Ã¼ber kÃ¼nstliche Intelligenz und ihre Auswirkungen."*

erstellt. Dieser Inhalt wird von beiden Agenten geprÃ¼ft und final gespeichert.

---

## ğŸ“‚ **Projektstruktur**

### **Hauptverzeichnis**

- **`README.md`**: Diese Datei mit allen Anweisungen und Beschreibungen.
- **`requirements.txt`**: Liste aller AbhÃ¤ngigkeiten fÃ¼r das Projekt.
- **`Ergebnisse/`**: Ordner, in dem die generierten Inhalte gespeichert werden.
- **`backend/`**: Beinhaltet die Hauptlogik des Projekts.

### **Backend-Verzeichnis**

Das `backend/`-Verzeichnis enthÃ¤lt folgende Dateien:

1. **`backend.py`**: Zentrale Steuerungseinheit fÃ¼r die Verarbeitung der Prompts und Generierung der Inhalte.
2. **`chatAgent.py`**: Implementierung der spezialisierten Validierungsagenten.
3. **`main.py`**: Einstiegspunkt fÃ¼r die AusfÃ¼hrung des Use Cases. Hier werden alle Module geladen und der Ablauf gesteuert.
4. **`agent.py`**: Kernkomponenten fÃ¼r die KI-Interaktion, die die Kommunikation zwischen Modell und Backend erleichtern.
5. **`duckduckgo.py`**: Modul zur Integration von externen Suchdiensten, um die Generierung mit zusÃ¤tzlichem Wissen zu unterstÃ¼tzen.
6. **`ollama.py`**: Ein Modul, das spezifisch fÃ¼r die Interaktion mit dem `dolphin3.0-llama3.1-8b` Modell optimiert wurde.

### **Ergebnisse-Verzeichnis**

- **`Use_Case_2.2.txt`**: Standarddatei, in der die Inhalte gespeichert werden, die aus diesem Use Case generiert wurden.

---

## ğŸ“ **Hinweis**

Dieses Projekt wurde so konzipiert, dass es lokal ausgefÃ¼hrt werden kann, um unnÃ¶tige Abfragen an externe Server zu vermeiden. Dies gewÃ¤hrleistet hÃ¶here Sicherheit und schnellere Verarbeitung.

---